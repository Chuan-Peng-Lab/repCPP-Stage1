{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import mne\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helper_function import *\n",
    "\n",
    "# print version\n",
    "print(mne.__version__)\n",
    "# set working directory\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subjidx in range(6):\n",
    "    for taskidx in range(3):\n",
    "        # Preprocess the raw data for the given subject and task.\n",
    "        raw = preprocess_raw_data(subjidx+1,taskidx+1)\n",
    "        # remove ica components\n",
    "        ica = mne.preprocessing.ICA(n_components=None, random_state=124,max_iter = 'auto')\n",
    "        ica.fit(raw)\n",
    "        #ica.exclude = [0,1] s1t1,2, s2t1,2\n",
    "        #ica.exclude = [0,1,2]    s1t1,3\n",
    "        #ica.exclude = [0,7] s3t1\n",
    "        #ica.exclude = [0,5] s3t2\n",
    "        #ica.exclude = [0,1,2] s4t1,2,3\n",
    "        #ica.exclude = [0,1] s5t1 \n",
    "        #ica.exclude = [0,1,4] s5t2\n",
    "        #ica.exclude = [0,3] s5t3\n",
    "        #ica.exclude = [0,1,2] s6t1,2,3\n",
    "        #ica.exclude = [0,1]\n",
    "\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(raw)                               \n",
    "        ica.exclude = eog_indices\n",
    "        ica.apply(raw)\n",
    "        raw.save(f'../2_Data/Preprocessed/sub-{subjidx+1:02d}_task-GTDT_run-{taskidx+1:02d}_eeg.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../2_Data/Preprocessed/sub-01_task-GTDT_run-01_eeg.fif...\n",
      "    Range : 0 ... 747417 =      0.000 ...  1459.799 secs\n",
      "Ready.\n",
      "Reading 0 ... 747417  =      0.000 ...  1459.799 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  9', 'Stimulus/S111', 'Stimulus/S112', 'Stimulus/S113']\n",
      "Not setting metadata\n",
      "75 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 75 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['F5']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "12 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-01_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 1153965 =      0.000 ...  2253.838 secs\n",
      "Ready.\n",
      "Reading 0 ... 1153965  =      0.000 ...  2253.838 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "30 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-01_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 903474 =      0.000 ...  1764.598 secs\n",
      "Ready.\n",
      "Reading 0 ... 903474  =      0.000 ...  1764.598 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "124 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 124 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "31 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-02_task-GTDT_run-01_eeg.fif...\n",
      "    Range : 0 ... 307813 =      0.000 ...   601.197 secs\n",
      "Ready.\n",
      "Reading 0 ... 307813  =      0.000 ...   601.197 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  9', 'Stimulus/S111', 'Stimulus/S112']\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-02_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 924630 =      0.000 ...  1805.918 secs\n",
      "Ready.\n",
      "Reading 0 ... 924630  =      0.000 ...  1805.918 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['F4']\n",
      "2 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-02_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 857026 =      0.000 ...  1673.879 secs\n",
      "Ready.\n",
      "Reading 0 ... 857026  =      0.000 ...  1673.879 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "124 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 124 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['F4', 'FT10', 'FC4', 'F6', 'AF8']\n",
      "1 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-03_task-GTDT_run-01_eeg.fif...\n",
      "    Range : 0 ... 274523 =      0.000 ...   536.178 secs\n",
      "Ready.\n",
      "Reading 0 ... 274523  =      0.000 ...   536.178 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  9', 'Stimulus/S111', 'Stimulus/S112']\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['T8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "5 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-03_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 859452 =      0.000 ...  1678.617 secs\n",
      "Ready.\n",
      "Reading 0 ... 859452  =      0.000 ...  1678.617 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "9 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-03_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 737218 =      0.000 ...  1439.879 secs\n",
      "Ready.\n",
      "Reading 0 ... 737218  =      0.000 ...  1439.879 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "124 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 124 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF4', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'PO8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'FC6', 'FC4', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'O2', 'PO4', 'AF7', 'AF8', 'PO7', 'PO8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "98 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-04_task-GTDT_run-01_eeg.fif...\n",
      "    Range : 0 ... 287958 =      0.000 ...   562.418 secs\n",
      "Ready.\n",
      "Reading 0 ... 287958  =      0.000 ...   562.418 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  9', 'Stimulus/S111', 'Stimulus/S112']\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "8 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-04_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 934768 =      0.000 ...  1825.719 secs\n",
      "Ready.\n",
      "Reading 0 ... 934768  =      0.000 ...  1825.719 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['TP10']\n",
      "    Rejecting  epoch based on EEG : ['TP10']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['TP10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['TP10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "26 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-04_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 722656 =      0.000 ...  1411.438 secs\n",
      "Ready.\n",
      "Reading 0 ... 722656  =      0.000 ...  1411.438 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "124 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 124 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['TP9']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'AF7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "13 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-05_task-GTDT_run-01_eeg.fif...\n",
      "    Range : 0 ... 312247 =      0.000 ...   609.857 secs\n",
      "Ready.\n",
      "Reading 0 ... 312247  =      0.000 ...   609.857 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  9', 'Stimulus/S111', 'Stimulus/S112']\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['PO8']\n",
      "7 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-05_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 783523 =      0.000 ...  1530.318 secs\n",
      "Ready.\n",
      "Reading 0 ... 783523  =      0.000 ...  1530.318 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['O1', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F3', 'C3', 'P3', 'F7', 'F8', 'T7', 'T8', 'FC5', 'CP5', 'FT9', 'TP9', 'C1', 'FC3', 'CP3', 'F5', 'C5', 'P5', 'FT7', 'FT8', 'TP7']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'FT9', 'FT10', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF7', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF7', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'O1', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['AF8']\n",
      "    Rejecting  epoch based on EEG : ['AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8', 'PO7']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'PO7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF7', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'O1', 'F7', 'F8', 'T7', 'T8', 'C1', 'C5', 'AF8', 'FT7', 'FT8', 'TP7']\n",
      "62 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-05_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 653577 =      0.000 ...  1276.518 secs\n",
      "Ready.\n",
      "Reading 0 ... 653577  =      0.000 ...  1276.518 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "124 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 124 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EEG : ['PO7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['PO7']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['O1']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F4', 'F6', 'AF8']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['PO7']\n",
      "35 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-06_task-GTDT_run-01_eeg.fif...\n",
      "    Range : 0 ... 321125 =      0.000 ...   627.197 secs\n",
      "Ready.\n",
      "Reading 0 ... 321125  =      0.000 ...   627.197 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  9', 'Stimulus/S111', 'Stimulus/S112']\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'FT10', 'AF7', 'Fpz']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "15 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-06_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 1025197 =      0.000 ...  2002.338 secs\n",
      "Ready.\n",
      "Reading 0 ... 1025197  =      0.000 ...  2002.338 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 151 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10', 'AF7']\n",
      "    Rejecting  epoch based on EEG : ['FT10', 'AF3', 'AF7']\n",
      "    Rejecting  epoch based on EEG : ['FT10', 'AF3']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10', 'AF3', 'AF7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10', 'AF7']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EEG : ['FT10', 'AF7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp2', 'F3', 'C3', 'C4', 'F7', 'F8', 'T7', 'T8', 'P7', 'FC2', 'FC5', 'FC6', 'CP5', 'FT9', 'FT10', 'TP9', 'C2', 'FC3', 'FC4', 'CP3', 'CP4', 'F5', 'F6', 'C5', 'P5', 'AF7', 'AF8', 'FT7', 'FT8', 'TP7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT10']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "66 bad epochs dropped\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-06_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 929791 =      0.000 ...  1815.998 secs\n",
      "Ready.\n",
      "Reading 0 ... 929791  =      0.000 ...  1815.998 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "124 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 124 events and 1409 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'Fpz']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EEG : ['FT9', 'FT10', 'AF7']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "    Rejecting  epoch based on EOG : ['EOG']\n",
      "29 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "drops = []\n",
    "event_num = []\n",
    "for subjidx in range(6):\n",
    "    for taskidx in range(3):\n",
    "        file_path = f'../2_Data/Preprocessed/sub-{subjidx+1:02d}_task-GTDT_run-{taskidx+1:02d}_eeg.fif'\n",
    "        raw = mne.io.read_raw_fif(file_path, preload=True)\n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "        # cause the marker of square appear twice, we only need the first marker\n",
    "        for i in range(len(events[:,2])):\n",
    "            if events[:,2][i]==9 and events[:,2][i+1]==9:\n",
    "                events[:,2][i] = 99\n",
    "        # cause the marker of response appear twice in some trials, we only need the first marker\n",
    "        for i in range(len(events[:,2])):\n",
    "            if events[:,2][i]==2 and events[:,2][i+1]==2:\n",
    "                events[:,2][i+1] = 22\n",
    "        # set the marker\n",
    "        stim_ids = {'Stimulus/S  1':1} # the marker of circle onset\n",
    "        resp_ids = {'Stimulus/S  2':2} # the marker of response\n",
    "        sq_ids = {'Stimulus/S  9':9} # the marker of square onset\n",
    "\n",
    "        # circle onset-locked epochs\n",
    "        tmin, tmax = -0.75, 2 # the time segment for epochs \n",
    "        baseline = (-0.5, 0) # the time window for baseline correction\n",
    "        epochs_stim = mne.Epochs(raw, events, stim_ids, tmin=tmin,picks=['eeg','eog'], tmax=tmax, reject=dict(eeg=100e-6,eog=200e-6),baseline=baseline) \n",
    "        event_num.append(len(epochs_stim.events))\n",
    "        epochs_stim.get_data()\n",
    "        rejected_epochs_indices = [i for i, log in enumerate(epochs_stim.drop_log) if log and 'IGNORED' not in log]\n",
    "        drops.append(rejected_epochs_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the final data\n",
    "df = pd.DataFrame()\n",
    "# Loop through each subject\n",
    "cpp_erp = np.empty([6,75,1024])\n",
    "lhb_erp = np.empty([6,75,1024])\n",
    "\n",
    "for subjidx in range(6):\n",
    "    # Adjust the subject index to start from 1 instead of 0\n",
    "    subjidx = subjidx+1\n",
    "    # Define the file path for the EEG data and load the EEG data using MNE\n",
    "    file_path = f'../2_Data/Preprocessed/sub-{subjidx:02d}_task-GTDT_run-01_eeg.fif'\n",
    "    raw = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    # Define the folder and file name for the behavioral data   \n",
    "    folder = 'PreData'\n",
    "    task = os.path.join('sub-'+str(subjidx).zfill(2)+'_task-GTDT_run-01_beh.csv')\n",
    "    filename_beh = os.path.join(folder,'sub-'+str(subjidx).zfill(2),task)\n",
    "    # Initialize a temporary DataFrame to store the subject's data.\n",
    "    temp_data = pd.DataFrame(columns=[\n",
    "        'subj_index',\n",
    "        'subj_idx',\n",
    "        'rt', \n",
    "        'amp_cpp',    \n",
    "        'amp_cum_ssvep', \n",
    "    ])\n",
    "    # Find and annotate events in the EEG data.\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "    # cause the marker of square appear twice, we only need the first marker\n",
    "    for i in range(len(events[:,2])):\n",
    "        if events[:,2][i]==9 and events[:,2][i+1]==9:\n",
    "            events[:,2][i] = 99\n",
    "    # cause the marker of response appear twice in some trials, we only need the first marker\n",
    "    for i in range(len(events[:,2])):\n",
    "        if events[:,2][i]==2 and events[:,2][i+1]==2:\n",
    "            events[:,2][i+1] = 22\n",
    "    # set the marker\n",
    "    stim_ids = {'Stimulus/S  1':1} # the marker of circle onset\n",
    "    resp_ids = {'Stimulus/S  2':2} # the marker of response\n",
    "    sq_ids = {'Stimulus/S  9':9} # the marker of square onset\n",
    "\n",
    "    # circle onset-locked epochs\n",
    "    tmin, tmax = -0.75, 2 # the time segment for epochs \n",
    "    baseline = (-0.5, 0) # the time window for baseline correction\n",
    "    epochs_stim = mne.Epochs(raw, events, stim_ids, tmin=tmin,picks='eeg', tmax=tmax, baseline=baseline) \n",
    "\n",
    "    # prepare the single trial data, we need to choose the roi and average them\n",
    "    electrodes = ['CPz','CP1','CP2'] # the electrodes of CPP\n",
    "    epochs_stim.load_data() # load epoch\n",
    "    epochs_stim_cpp = pd.DataFrame(epochs_stim.copy().pick_channels(electrodes).get_data().mean(axis=1)) # select roi and average them\n",
    "    dfs_stim = pd.read_csv(filename_beh,sep=',',index_col=0) # read the behavioral data\n",
    "    epochs_stim_cpp['rt'] = dfs_stim.loc[dfs_stim['RtTimes']==1,'Rt'].reset_index(drop=True).replace(np.nan,0) # get the rt of first response and replace NA to 0\n",
    "\n",
    "    epochs_stim_cpp = epochs_stim_cpp.sort_values(by=['rt'],ascending=True) # sort epochs by value of rt\n",
    "    # plot the dynamics of the stim-locked CPP\n",
    "    cpp = epochs_stim.average().to_data_frame() # average the epochs\n",
    "    cpp['value'] = np.mean(cpp[electrodes],axis=1) # average the electrodes\n",
    "\n",
    "    # resp-locked epochs\n",
    "    tmin, tmax = -1.2, 0.4 # the time segment for epochs \n",
    "    epochs_resp = mne.Epochs(raw, events, resp_ids, tmin=tmin,picks='eeg', tmax=tmax)\n",
    "\n",
    "    # Preparing the single trial data\n",
    "    # Selecting the electrodes of CPP\n",
    "    electrodes = ['CPz','CP1','CP2'] \n",
    "    # Loading the epoch data\n",
    "    epochs_resp.load_data()\n",
    "    # Selecting the region of interest (ROI) and averaging the data\n",
    "    epochs_resp_cpp = pd.DataFrame(epochs_resp.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
    "    # Reading the behavioral data\n",
    "    dfs_stim = pd.read_csv(filename_beh,sep=',',index_col=0)\n",
    "    # Getting the response time (rt) of the first response and replacing NA with 0\n",
    "    epochs_resp_cpp['rt'] = dfs_stim.loc[(dfs_stim['RtTimes']==1)&(dfs_stim['Rt'].notna()),'Rt'].reset_index(drop=True).replace(np.nan,0)\n",
    "    # Getting the squared response time (rtsquare) of the first response and replacing NA with 0\n",
    "    epochs_resp_cpp['rtsquare'] = dfs_stim.loc[(dfs_stim['RtTimes']==1)&(dfs_stim['RtSquare'].notna()),'RtSquare'].reset_index(drop=True).replace(np.nan,0)\n",
    "    # Sorting epochs by value of rt (response time)\n",
    "    epochs_resp_cpp = epochs_resp_cpp.sort_values(by=['rt'],ascending=True)\n",
    "\n",
    "    # Calculate the amplitude of the CPP component for each trial within a specific time window around the reaction time.\n",
    "    cppdata = []\n",
    "    for i in range(len(temp_data)):\n",
    "        # Calculate the mean amplitude within the time window for each trial and add it to the 'cppdata' list.\n",
    "        cppdata.append(np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75 - 0.05) * 512):int((0.75 + 0.05 + temp_data['rt'][i]) * 512)].mean(axis=1)[i])\n",
    "    #\n",
    "    if np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 75:\n",
    "        cpp_erp[subjidx - 1][:np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
    "        cpp_erp[subjidx - 1][np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
    "    \n",
    "    else:\n",
    "        # Store the averaged event-related potential (ERP) data for CPP in the 'cpp_erp' array.\n",
    "        cpp_erp[subjidx - 1] = np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Setting the time window for the CPP amplitude\n",
    "    tw = [-0.05,0.05]\n",
    "    # Calculating the mean amplitude of the CPP within the defined time window \n",
    "    temp_data['amp_cpp']=epochs_resp_cpp.loc[:,int((1.2+tw[0])*512):int((1.2+tw[1])*512)].mean(axis=1)\n",
    "    # Sorting the data by index\n",
    "    temp_data = temp_data.sort_index()\n",
    "    # Adding the response time to the data\n",
    "    temp_data['rt']=epochs_resp_cpp['rt']\n",
    "    # Preparing for the ssvep analysis\n",
    "    # Selecting the electrodes\n",
    "    electrodes = ['Oz', 'O1', 'O2', 'POz', 'PO3', 'PO4']\n",
    "    # Creating a copy of the raw data and selecting the channels\n",
    "    sraw = raw.copy()\n",
    "    sraw = sraw.pick_channels(electrodes)\n",
    "    # Defining the ssvep frequencies\n",
    "    ssvep_freq = np.array([21.25,22])\n",
    "    # Defining the time segment for epochs \n",
    "    tmin, tmax = -0.75, 2 \n",
    "    # Creating epochs\n",
    "    sepochs = mne.Epochs(sraw, events , stim_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Performing a morlet wavelet transform on the epochs\n",
    "    tfr = mne.time_frequency.tfr_morlet(sepochs, freqs=ssvep_freq,picks='all',\n",
    "                                n_cycles=ssvep_freq/2, return_itc=False,average=False)\n",
    "    # Defining the time segment for epochs \n",
    "    tmin, tmax = -1.2, 0.4  \n",
    "    # Creating epochs for responses\n",
    "    sepochs_resp = mne.Epochs(sraw, events , resp_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Performing a morlet wavelet transform on the response epochs\n",
    "    tfr_resp = mne.time_frequency.tfr_morlet(sepochs_resp, freqs=ssvep_freq,picks='all',\n",
    "                                n_cycles=ssvep_freq/2, return_itc=False,average=False)\n",
    "    # Calculating the cumulative sum of the mean power of the ssvep response\n",
    "    ssvepdata = np.cumsum(np.mean(np.mean(tfr_resp.data,axis=1),axis=1)[:,0:int(1.2*512)],axis=1)[:,-1]\n",
    "    # Adding the calculated ssvep amplitude to the data\n",
    "    temp_data['amp_cum_ssvep'] = ssvepdata\n",
    "    # Adding the subject index to the data\n",
    "    temp_data['subj_idx'] = subjidx \n",
    "    # Adding a column for the subject index\n",
    "    temp_data['subj_index'] = np.arange(len(temp_data)) \n",
    "    # Concatenating the data with the existing dataframe\n",
    "    df=pd.concat([df,temp_data])\n",
    "\n",
    "   # Prepare data for LHB analysis.\n",
    "    # Define the time window (in seconds) for extracting epochs.\n",
    "    tmin, tmax = -0.75, 2\n",
    "    # Define the electrodes to be used.\n",
    "    electrodes =['C3', 'C1', 'C5']\n",
    "    # Creating a copy of the raw data and selecting the channels\n",
    "    sraw = raw.copy()\n",
    "    sraw = sraw.pick_channels(electrodes)\n",
    "    # Defining the ssvep frequencies\n",
    "    ssvep_freq = np.array([21.25,22])\n",
    "    # Defining the time segment for epochs \n",
    "    tmin, tmax = -0.75, 2 \n",
    "    # Define the frequencies of interest for the time-frequency representation.\n",
    "    freqs = np.linspace(22, 30, 10)\n",
    "    # Creating epochs\n",
    "    sepochs = mne.Epochs(sraw, events , stim_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Perform time-frequency decomposition on the concatenated epochs using Morlet wavelets.\n",
    "    tfr = mne.time_frequency.tfr_morlet(sepochs, freqs=freqs,picks='all',\n",
    "                                    n_cycles=8, return_itc=False,average=False)\n",
    "    tfr_resp = mne.time_frequency.tfr_morlet(sepochs_resp, freqs=ssvep_freq,picks='all',\n",
    "                                    n_cycles=8, return_itc=False,average=False)\n",
    "    # Initialize an empty list to store LHB data.\n",
    "    lhbdata = []\n",
    "    # Loop through each element in temp_data to calculate the mean power based on reaction time (rt).\n",
    "    for i in range(len(temp_data)):\n",
    "        lhbdata.append(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int((0.75-0.05)*512):int((0.75+0.05+temp_data['rt'][i])*512)].mean())\n",
    "    if np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 75:\n",
    "        lhb_erp[subjidx - 1][:np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)].shape[0]] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "        lhb_erp[subjidx - 1][np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)].shape[0]:] = np.nan\n",
    "    \n",
    "    else:\n",
    "        # Calculate the average power across channels and epochs for a fixed interval after 0.75 seconds and assign it to lhb_erp.\n",
    "        lhb_erp[subjidx-1] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "df.to_csv('df_task1.csv',index=False)\n",
    "# Save the ERP data and the combined DataFrame to files for later use.\n",
    "np.save('df_task1_lhb',lhb_erp)\n",
    "np.save('df_task1_cpp',cpp_erp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the combined data from all participants.\n",
    "df = pd.DataFrame()\n",
    "# Initialize empty arrays to store ERP data for each condition across all participants.\n",
    "cpp_erp = np.empty([6,150,1024])\n",
    "lhb_erp = np.empty([6,150,1024])\n",
    "ssvep_erp = np.empty([6,150,1024])\n",
    "cpp_erp_resp = []\n",
    "lhb_erp_resp = []\n",
    "ssvep_erp_resp = []\n",
    "# Loop over the participant indices.\n",
    "for subjidx in range(6):\n",
    "    # Increment subject index to start from 1.\n",
    "    subjidx = subjidx+1\n",
    "    # Load EEG data for runs 2 and 3.\n",
    "    file_path = f'../2_Data/Preprocessed/sub-{subjidx:02d}_task-GTDT_run-02_eeg.fif'\n",
    "    raw2 = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "    file_path = f'../2_Data/Preprocessed/sub-{subjidx:02d}_task-GTDT_run-03_eeg.fif'\n",
    "    raw3 = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "    taskidx = 2\n",
    "    folder = 'PreData'\n",
    "    task = os.path.join('sub-'+os.path.join(str(subjidx).zfill(2))+'_task-GTDT'+'_run-'+str(taskidx).zfill(2)+'_beh.csv')\n",
    "    filename_beh2 = os.path.join(folder,'sub-'+str(subjidx).zfill(2),task)\n",
    "\n",
    "    # Load behavioral data for runs 2 and 3.\n",
    "    taskidx = 3\n",
    "    folder = 'PreData'\n",
    "    task = os.path.join('sub-'+os.path.join(str(subjidx).zfill(2))+'_task-GTDT'+'_run-'+str(taskidx).zfill(2)+'_beh.csv')\n",
    "    filename_beh3 = os.path.join(folder,'sub-'+str(subjidx).zfill(2),task)\n",
    "\n",
    "    # Process events for runs 2 and 3, marking segments that should be treated as a single condition.\n",
    "    events2, event_id = mne.events_from_annotations(raw2)\n",
    "    arr = events2[:,2]\n",
    "    six_indices = np.where(arr == 6)[0]\n",
    "    segment_start = []\n",
    "    segment_end = []\n",
    "\n",
    "    for i in range(len(six_indices) - 1):\n",
    "        start = six_indices[i] \n",
    "        end = six_indices[i + 1]\n",
    "        \n",
    "        # Check if segment contains only 1s\n",
    "        if np.all(arr[start+1:end] == 1) and len(arr[start+1:end])!=0:\n",
    "            segment_start.append(start+1)\n",
    "            segment_end.append(end)\n",
    "    for start, end in zip(segment_start, segment_end):\n",
    "        events2[:,2][start:end] = 11\n",
    "\n",
    "\n",
    "    events3, event_id = mne.events_from_annotations(raw3)\n",
    "    arr = events3[:,2]\n",
    "    six_indices = np.where(arr == 6)[0]\n",
    "    segment_start = []\n",
    "    segment_end = []\n",
    "\n",
    "    for i in range(len(six_indices) - 1):\n",
    "        start = six_indices[i] \n",
    "        end = six_indices[i + 1]\n",
    "        \n",
    "        # Check if segment contains only 1s\n",
    "        if np.all(arr[start+1:end] == 1) and len(arr[start+1:end])!=0:\n",
    "            segment_start.append(start+1)\n",
    "            segment_end.append(end)\n",
    "    for start, end in zip(segment_start, segment_end):\n",
    "        events3[:,2][start:end] = 11\n",
    "\n",
    "    # Define the identifiers for different types of events.\n",
    "    stim_ids = {'Stimulus/S  1':1}\n",
    "    resp_ids = {'Stimulus/S  2':2}\n",
    "    count_ids = {'Stimulus/S  11':11}\n",
    "    # Create epochs for stimulus events for runs 2 and 3 and concatenate them.\n",
    "    tmin, tmax = -0.75, 2\n",
    "    baseline = (-0.5, 0)\n",
    "    epochs_stim2 = mne.Epochs(raw2, events2, stim_ids, tmin=tmin,picks='eeg', tmax=tmax, baseline=baseline)\n",
    "    epochs_stim3 = mne.Epochs(raw3, events3, stim_ids, tmin=tmin,picks='eeg', tmax=tmax, baseline=baseline)\n",
    "    epochs_stim = mne.concatenate_epochs([epochs_stim2, epochs_stim3])\n",
    "    tmin, tmax = -1.5, 0.5\n",
    "    epochs_resp2 = mne.Epochs(raw2, events2, resp_ids, tmin=tmin,picks='eeg', tmax=tmax)\n",
    "    epochs_resp3 = mne.Epochs(raw3, events3, resp_ids, tmin=tmin,picks='eeg', tmax=tmax)\n",
    "    epochs_resp = mne.concatenate_epochs([epochs_resp2, epochs_resp3])\n",
    "\n",
    "\n",
    "    # Prepare data for CPP analysis.\n",
    "    # Select electrodes associated with the Central Parietal Positivity (CPP) component.\n",
    "    electrodes = ['CPz', 'CP1', 'CP2']\n",
    "    # Load the epoch data into memory for further processing.\n",
    "    epochs_stim.load_data()\n",
    "    # Create a DataFrame from the epochs by averaging the signals across the selected electrodes.\n",
    "    # This step isolates the CPP component for each trial.\n",
    "    epochs_stim_cpp = pd.DataFrame(epochs_stim.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
    "\n",
    "    # Load the epoch data into memory for further processing.\n",
    "    epochs_resp.load_data()\n",
    "    # Create a DataFrame from the epochs by averaging the signals across the selected electrodes.\n",
    "    # This step isolates the CPP component for each trial.\n",
    "    cpp_erp_resp.append(np.mean(epochs_resp.copy().pick_channels(electrodes).get_data(), axis=1)) \n",
    "    # Load the behavioral data from the CSV file.\n",
    "    dfs_stim = pd.read_csv(filename_beh2, sep=',', index_col=0)\n",
    "    # Extract reaction times (RT) from the behavioral data, corresponding to the first response times.\n",
    "    # Replace missing values (NaN) with 0.\n",
    "    epochs_stim_cpp['rt'] = dfs_stim.loc[dfs_stim['RtTimes'] == 1, 'Rt'].reset_index(drop=True).replace(np.nan, 0)\n",
    "    # Sort the trials by reaction time.\n",
    "    epochs_stim_cpp = epochs_stim_cpp.sort_values(by=['rt'], ascending=True)\n",
    "    # Initialize a temporary DataFrame to store additional data for each trial.\n",
    "    temp_data = pd.DataFrame(columns=[\n",
    "        'subj_index',        # Index of the subject within the study.\n",
    "        'subj_idx',          # Identifier of the subject.\n",
    "        'rt',                # Reaction time.\n",
    "        'amp_cpp',           # Amplitude of the CPP component.\n",
    "        'amp_lhb',           # Amplitude of the left hemisphere beta activity (placeholder, to be calculated later).\n",
    "        'amp_cum_ssvep',     # Cumulative amplitude of the SSVEP (placeholder, to be calculated later).\n",
    "    ])\n",
    "    # Set the time window for calculating the CPP amplitude.\n",
    "    tmin, tmax = -0.75, 2\n",
    "    tw = [-0.05, 0.05]\n",
    "    # Sort the temporary DataFrame by index.\n",
    "    temp_data = temp_data.sort_index()\n",
    "    # Add reaction times to the temporary DataFrame.\n",
    "    temp_data['rt'] = epochs_stim_cpp['rt']\n",
    "    # Sort the temporary DataFrame again after adding the reaction times.\n",
    "    temp_data = temp_data.sort_index()\n",
    "    # Calculate the amplitude of the CPP component for each trial within a specific time window around the reaction time.\n",
    "    cppdata = []\n",
    "    for i in range(len(temp_data)):\n",
    "        # Calculate the mean amplitude within the time window for each trial and add it to the 'cppdata' list.\n",
    "        cppdata.append(np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75 - 0.05) * 512):int((0.75 + 0.05 + temp_data['rt'][i]) * 512)].mean(axis=1)[i])\n",
    "    # Store the averaged event-related potential (ERP) data for CPP in the 'cpp_erp' array.\n",
    "    cpp_erp[subjidx - 1] = np.mean(epochs_stim.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
    "\n",
    "    # Prepare data for SSVEP analysis.\n",
    "    electrodes = ['Oz', 'O1', 'O2', 'POz', 'PO3', 'PO4']\n",
    "    # Copy the raw2 object to sraw2 and select only the channels specified in 'electrodes'.\n",
    "    sraw2 = raw2.copy()\n",
    "    sraw2 = sraw2.pick_channels(electrodes)\n",
    "    # Copy the raw3 object to sraw3 and select only the channels specified in 'electrodes'.\n",
    "    sraw3 = raw3.copy()\n",
    "    sraw3 = sraw3.pick_channels(electrodes)\n",
    "    # Commented out line: This line would get the data from sraw if it was uncommented.\n",
    "    #sraw = sraw.get_data()\n",
    "    # Define the frequencies of interest for the SSVEP analysis.\n",
    "    ssvep_freq = [21.25,22]\n",
    "    # Create epochs from the sraw2 data based on events, time window, and baseline correction.\n",
    "    sepochs2 = mne.Epochs(sraw2, events2 , stim_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Create epochs from the sraw3 data based on events, time window, and baseline correction.\n",
    "    sepochs3 = mne.Epochs(sraw3, events3 , stim_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Concatenate the epochs from sraw2 and sraw3 into a single Epochs object.\n",
    "    sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n",
    "    # Create epochs from the sraw2 data based on events, time window, and baseline correction.\n",
    "    sepochs2_resp = mne.Epochs(sraw2, events2 , resp_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs3_resp = mne.Epochs(sraw3, events3 , resp_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs_resp = mne.concatenate_epochs([sepochs2_resp, sepochs3_resp])\n",
    "\n",
    "    # Perform time-frequency decomposition using Morlet wavelets on the concatenated epochs.\n",
    "    tfr = mne.time_frequency.tfr_morlet(sepochs, freqs=ssvep_freq,picks='all',\n",
    "                                    n_cycles=8, return_itc=False,average=False)\n",
    "    tfr_resp = mne.time_frequency.tfr_morlet(sepochs_resp, freqs=ssvep_freq,picks='all',\n",
    "                                    n_cycles=8, return_itc=False,average=False)\n",
    "    # Initialize an empty list to store cumulative data.\n",
    "    ssvepcumdata = []\n",
    "    # Loop through each element in temp_data to calculate cumulative data based on reaction time (rt).\n",
    "    for i in range(len(temp_data)):\n",
    "        # Calculate the cumulative sum of the average power across channels and epochs after 0.75 seconds.\n",
    "        # If the resulting shape is 0, assign NaN, otherwise assign the cumulative sum of the last element.\n",
    "        if np.cumsum(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+temp_data['rt'][i])*512)],axis=1).shape[1]==0:\n",
    "            value = np.nan\n",
    "        else:\n",
    "            value = np.cumsum(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+temp_data['rt'][i])*512)],axis=1)[i,-1]\n",
    "        # Append the calculated value to the ssvepcumdata list.\n",
    "        ssvepcumdata.append(value)\n",
    "    # Calculate the average power across channels and epochs for a fixed interval after 0.75 seconds and assign it to ssvep_erp.\n",
    "    ssvep_erp[subjidx-1] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "    ssvep_erp_resp.append(np.mean(np.mean(tfr_resp.data,axis=1),axis=1))\n",
    "    # Initialize an empty list to store SSVEP data.\n",
    "    ssvepdata = []\n",
    "    # Loop through each element in temp_data to calculate the mean power based on reaction time (rt).\n",
    "    for i in range(len(temp_data)):\n",
    "        # Calculate and append the mean of the average power across channels and epochs for each reaction time.\n",
    "        ssvepdata.append(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int((0.75-0.05)*512):int((0.75+0.05+temp_data['rt'][i])*512)].mean())\n",
    "\n",
    "    # Prepare data for LHB analysis.\n",
    "    # Define the time window (in seconds) for extracting epochs.\n",
    "    tmin, tmax = -0.75, 2\n",
    "    # Define the electrodes to be used.\n",
    "    electrodes =['C3', 'C1', 'C5']\n",
    "    # Copy data from raw2 to sraw2 and select channels specified in 'electrodes'.\n",
    "    sraw2 = raw2.copy()\n",
    "    sraw2 = sraw2.pick_channels(electrodes)\n",
    "    # Copy data from raw3 to sraw3 and select channels specified in 'electrodes'.\n",
    "    sraw3 = raw3.copy()\n",
    "    sraw3 = sraw3.pick_channels(electrodes)\n",
    "    # Define the frequencies of interest for the time-frequency representation.\n",
    "    freqs = np.linspace(22, 30, 10)\n",
    "    # Create epochs from the sraw2 data based on events, time window, and baseline correction.\n",
    "    sepochs2 = mne.Epochs(sraw2, events2 , stim_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Create epochs from the sraw3 data based on events, time window, and baseline correction.\n",
    "    sepochs3 = mne.Epochs(sraw3, events3 , stim_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    # Concatenate the epochs from sraw2 and sraw3 into a single Epochs object.\n",
    "    sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n",
    "    sepochs2_resp = mne.Epochs(sraw2, events2 , resp_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs3_resp = mne.Epochs(sraw3, events3 , resp_ids, tmin=tmin,picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs_resp = mne.concatenate_epochs([sepochs2_resp, sepochs3_resp])\n",
    "    # Perform time-frequency decomposition on the concatenated epochs using Morlet wavelets.\n",
    "    tfr = mne.time_frequency.tfr_morlet(sepochs, freqs=freqs,picks='all',\n",
    "                                    n_cycles=8, return_itc=False,average=False)\n",
    "    tfr_resp = mne.time_frequency.tfr_morlet(sepochs_resp, freqs=ssvep_freq,picks='all',\n",
    "                                    n_cycles=8, return_itc=False,average=False)\n",
    "    # Initialize an empty list to store LHB data.\n",
    "    lhbdata = []\n",
    "    # Loop through each element in temp_data to calculate the mean power based on reaction time (rt).\n",
    "    for i in range(len(temp_data)):\n",
    "        lhbdata.append(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int((0.75-0.05)*512):int((0.75+0.05+temp_data['rt'][i])*512)].mean())\n",
    "    # Calculate the average power across channels and epochs for a fixed interval after 0.75 seconds and assign it to lhb_erp.\n",
    "    lhb_erp[subjidx-1] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "    lhb_erp_resp.append(np.mean(np.mean(tfr_resp.data,axis=1),axis=1))\n",
    "    # Add SSVEP, LHB, and CPP data to the temp_data DataFrame.\n",
    "    temp_data['amp_ssvep'] = ssvepdata\n",
    "    temp_data['amp_cum_ssvep'] = ssvepcumdata\n",
    "    temp_data['pl_ssvep'] =np.argmax(ssvep_erp[subjidx-1],axis=1)/521\n",
    "    temp_data['pl_lhb'] =np.argmax(lhb_erp[subjidx-1],axis=1)/512\n",
    "    temp_data['pl_cpp'] =np.argmax(cpp_erp[subjidx-1],axis=1)/512\n",
    "    temp_data['amp_lhb'] = lhbdata\n",
    "    temp_data['amp_cpp'] = cppdata\n",
    "    # Add subject index to the temp_data DataFrame.\n",
    "    temp_data['subj_idx'] = subjidx \n",
    "    temp_data['subj_index'] = np.arange(len(temp_data)) \n",
    "    # Concatenate temp_data with the existing DataFrame df.\n",
    "    df=pd.concat([df,temp_data]) \n",
    "# Save the ERP data and the combined DataFrame to files for later use.\n",
    "np.save('df_task2_lhb',lhb_erp)\n",
    "np.save('df_task2_cpp',cpp_erp)\n",
    "np.save('df_task2_ssvep',ssvep_erp)\n",
    "np.save('df_task2_lhb_resp',lhb_erp_resp)\n",
    "np.save('df_task2_cpp_resp',cpp_erp_resp)\n",
    "np.save('df_task2_ssvep_resp',ssvep_erp_resp)\n",
    "df.to_csv('df_task2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../2_Data/Preprocessed/sub-01_task-GTDT_run-02_eeg.fif...\n",
      "    Range : 0 ... 1153965 =      0.000 ...  2253.838 secs\n",
      "Ready.\n",
      "Reading 0 ... 1153965  =      0.000 ...  2253.838 secs...\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-01_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 903474 =      0.000 ...  1764.598 secs\n",
      "Ready.\n",
      "Reading 0 ... 903474  =      0.000 ...  1764.598 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:107: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw2 = sraw2.pick_channels(electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:109: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw3 = sraw3.pick_channels(electrodes)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:115: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:131: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-02_task-GTDT_run-02_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:137: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 924630 =      0.000 ...  1805.918 secs\n",
      "Ready.\n",
      "Reading 0 ... 924630  =      0.000 ...  1805.918 secs...\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-02_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 857026 =      0.000 ...  1673.879 secs\n",
      "Ready.\n",
      "Reading 0 ... 857026  =      0.000 ...  1673.879 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:107: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw2 = sraw2.pick_channels(electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:109: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw3 = sraw3.pick_channels(electrodes)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:115: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:131: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-03_task-GTDT_run-02_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:137: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 859452 =      0.000 ...  1678.617 secs\n",
      "Ready.\n",
      "Reading 0 ... 859452  =      0.000 ...  1678.617 secs...\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-03_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 737218 =      0.000 ...  1439.879 secs\n",
      "Ready.\n",
      "Reading 0 ... 737218  =      0.000 ...  1439.879 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:107: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw2 = sraw2.pick_channels(electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:109: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw3 = sraw3.pick_channels(electrodes)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:115: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:131: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-04_task-GTDT_run-02_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:137: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 934768 =      0.000 ...  1825.719 secs\n",
      "Ready.\n",
      "Reading 0 ... 934768  =      0.000 ...  1825.719 secs...\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-04_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 722656 =      0.000 ...  1411.438 secs\n",
      "Ready.\n",
      "Reading 0 ... 722656  =      0.000 ...  1411.438 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:107: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw2 = sraw2.pick_channels(electrodes)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:109: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw3 = sraw3.pick_channels(electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:115: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:131: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-05_task-GTDT_run-02_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:137: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 783523 =      0.000 ...  1530.318 secs\n",
      "Ready.\n",
      "Reading 0 ... 783523  =      0.000 ...  1530.318 secs...\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-05_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 653577 =      0.000 ...  1276.518 secs\n",
      "Ready.\n",
      "Reading 0 ... 653577  =      0.000 ...  1276.518 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:107: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw2 = sraw2.pick_channels(electrodes)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:109: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw3 = sraw3.pick_channels(electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:115: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:131: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-06_task-GTDT_run-02_eeg.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:137: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 1025197 =      0.000 ...  2002.338 secs\n",
      "Ready.\n",
      "Reading 0 ... 1025197  =      0.000 ...  2002.338 secs...\n",
      "Opening raw data file ../2_Data/Preprocessed/sub-06_task-GTDT_run-03_eeg.fif...\n",
      "    Range : 0 ... 929791 =      0.000 ...  1815.998 secs\n",
      "Ready.\n",
      "Reading 0 ... 929791  =      0.000 ...  1815.998 secs...\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Non-RawBrainVision raw using branvision markers\n",
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:78: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:86: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:93: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:94: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:95: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:107: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw2 = sraw2.pick_channels(electrodes)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:109: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  sraw3 = sraw3.pick_channels(electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "51 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "74 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 51 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 74 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "125 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:115: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "0 bad epochs dropped\n",
      "Using data from preloaded Raw for 100 events and 1409 original time points ...\n",
      "Using data from preloaded Raw for 50 events and 1409 original time points ...\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:131: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3848\\2267241928.py:137: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# Initialize empty arrays to store ERP data for each condition across all participants.\n",
    "cpp_erp = np.empty([6,150,1024])\n",
    "lhb_erp = np.empty([6,150,1024])\n",
    "ssvep_erp = np.empty([6,150,1024])\n",
    "\n",
    "for subjidx in range(6):\n",
    "    # Increment subject index to start from 1.\n",
    "    subjidx = subjidx+1\n",
    "    # Load EEG data for runs 2 and 3.\n",
    "    file_path = f'../2_Data/Preprocessed/sub-{subjidx:02d}_task-GTDT_run-02_eeg.fif'\n",
    "    raw2 = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "    file_path = f'../2_Data/Preprocessed/sub-{subjidx:02d}_task-GTDT_run-03_eeg.fif'\n",
    "    raw3 = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "    taskidx = 2\n",
    "    folder = 'PreData'\n",
    "    task = os.path.join('sub-'+os.path.join(str(subjidx).zfill(2))+'_task-GTDT'+'_run-'+str(taskidx).zfill(2)+'_beh.csv')\n",
    "    filename_beh2 = os.path.join(folder,'sub-'+str(subjidx).zfill(2),task)\n",
    "\n",
    "    # Load behavioral data for runs 2 and 3.\n",
    "    taskidx = 3\n",
    "    folder = 'PreData'\n",
    "    task = os.path.join('sub-'+os.path.join(str(subjidx).zfill(2))+'_task-GTDT'+'_run-'+str(taskidx).zfill(2)+'_beh.csv')\n",
    "    filename_beh3 = os.path.join(folder,'sub-'+str(subjidx).zfill(2),task)\n",
    "    \n",
    "    # Extract events and their IDs from annotations in the raw2 EEG data.\n",
    "    events2, event_id = mne.events_from_annotations(raw2)\n",
    "    # Get the event codes from the events array.\n",
    "    arr = events2[:,2]\n",
    "    # Find indices where the event code is 6.\n",
    "    six_indices = np.where(arr == 6)[0]\n",
    "    # Initialize lists to store the start and end indices of segments.\n",
    "    segment_start = []\n",
    "    segment_end = []\n",
    "\n",
    "    # Loop through the indices to find segments that contain only the event code 1 between two event code 6.\n",
    "    for i in range(len(six_indices) - 1):\n",
    "        start = six_indices[i] \n",
    "        end = six_indices[i + 1]\n",
    "        \n",
    "        # Check if the segment between two indices of event code 6 contains only event code 1.\n",
    "        if np.all(arr[start+1:end] == 1) and len(arr[start+1:end])!=0:\n",
    "            segment_start.append(start+1)\n",
    "            segment_end.append(end)\n",
    "    # Mark these segments with the event code 11.\n",
    "    for start, end in zip(segment_start, segment_end):\n",
    "        events2[:,2][start:end] = 11\n",
    "\n",
    "    # Repeat the process for the raw3 EEG data.\n",
    "    events3, event_id = mne.events_from_annotations(raw3)\n",
    "    arr = events3[:,2]\n",
    "    six_indices = np.where(arr == 6)[0]\n",
    "    segment_start = []\n",
    "    segment_end = []\n",
    "\n",
    "    for i in range(len(six_indices) - 1):\n",
    "        start = six_indices[i] \n",
    "        end = six_indices[i + 1]\n",
    "        \n",
    "        if np.all(arr[start+1:end] == 1) and len(arr[start+1:end])!=0:\n",
    "            segment_start.append(start+1)\n",
    "            segment_end.append(end)\n",
    "    for start, end in zip(segment_start, segment_end):\n",
    "        events3[:,2][start:end] = 11\n",
    "\n",
    "    # Define dictionaries for stimulus, response, and count event IDs.\n",
    "    stim_ids = {'Stimulus/S  1':1}\n",
    "    resp_ids = {'Stimulus/S  2':2}\n",
    "    count_ids = {'Stimulus/S  11':11}\n",
    "\n",
    "    # Set the time window and baseline for epoch extraction.\n",
    "    tmin, tmax = -0.75, 2\n",
    "    baseline = (-0.5, 0)\n",
    "    # Create epochs for the count event (event code 11) from both raw2 and raw3 EEG data.\n",
    "    epochs_count2 = mne.Epochs(raw2, events2, count_ids, tmin=tmin,picks='eeg', tmax=tmax, baseline=baseline)\n",
    "    epochs_count3 = mne.Epochs(raw3, events3, count_ids, tmin=tmin,picks='eeg', tmax=tmax, baseline=baseline)\n",
    "    # Concatenate the epochs from both datasets into a single Epochs object.\n",
    "    epochs_count = mne.concatenate_epochs([epochs_count2, epochs_count3])\n",
    "    # Initialize an empty DataFrame.\n",
    "    temp_data = pd.DataFrame()\n",
    "    # Select the electrodes of interest for the CPP ERP component.\n",
    "    electrodes = ['CPz','CP1','CP2']\n",
    "    # Load the epochs data into memory.\n",
    "    epochs_count.load_data()\n",
    "    # Create a DataFrame with the mean data across the selected electrodes (roi).\n",
    "    epochs_count_cpp = pd.DataFrame(epochs_count.copy().pick_channels(electrodes).get_data().mean(axis=1))\n",
    "    # Define a time window and calculate the mean CPP amplitude within this window.\n",
    "    tw = [0,1.6]\n",
    "    temp_data['amp_cpp'] = epochs_count_cpp.loc[:,int((0.75+tw[0])*512):int((0.75+tw[1])*512)].mean(axis=1)\n",
    "    # Sort the DataFrame by index.\n",
    "    temp_data = temp_data.sort_index()\n",
    "\n",
    "    if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
    "        cpp_erp[subjidx - 1][:np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
    "        cpp_erp[subjidx - 1][np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0]:] = np.nan\n",
    "    \n",
    "    else:\n",
    "        # Store the averaged event-related potential (ERP) data for CPP in the 'cpp_erp' array.\n",
    "        cpp_erp[subjidx - 1] = np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)]\n",
    "\n",
    "\n",
    "\n",
    "    # Select the electrodes of interest for the SSVEP ERP component.\n",
    "    electrodes = ['Oz', 'O1', 'O2', 'POz', 'PO3', 'PO4']\n",
    "    # Copy raw2 data, select channels, and repeat for raw3.\n",
    "    sraw2 = raw2.copy()\n",
    "    sraw2 = sraw2.pick_channels(electrodes)\n",
    "    sraw3 = raw3.copy()\n",
    "    sraw3 = sraw3.pick_channels(electrodes)\n",
    "    # Define the SSVEP frequencies of interest.\n",
    "    ssvep_freq = [21.25,22]\n",
    "    # Create epochs from sraw2 and sraw3, then concatenate them.\n",
    "    sepochs2 = mne.Epochs(sraw2, events2 , count_ids, tmin=tmin, picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs3 = mne.Epochs(sraw3, events3 , count_ids, tmin=tmin, picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n",
    "    # Compute time-frequency representation using Morlet wavelets.\n",
    "    tfr = mne.time_frequency.tfr_morlet(sepochs, freqs=ssvep_freq, picks='all', n_cycles=8, return_itc=False, average=False)\n",
    "    # Calculate the cumulative sum of the mean power at the SSVEP frequencies.\n",
    "    ssvepdata = np.cumsum(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,0:int(1.6*512)],axis=1)[:,-1]\n",
    "    if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
    "        ssvep_erp[subjidx - 1][:np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)].shape[0]] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "        ssvep_erp[subjidx - 1][np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)].shape[0]:] = np.nan\n",
    "    \n",
    "    else:\n",
    "        # Calculate the average power across channels and epochs for a fixed interval after 0.75 seconds and assign it to lhb_erp.\n",
    "        ssvep_erp[subjidx-1] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "    \n",
    "    # Repeat the process for the LHB ERP component.\n",
    "    tmin, tmax = -0.75, 2\n",
    "    electrodes =['C3', 'C1', 'C5']\n",
    "    sraw2 = raw2.copy()\n",
    "    sraw2 = sraw2.pick_channels(electrodes)\n",
    "    sraw3 = raw3.copy()\n",
    "    sraw3 = sraw3.pick_channels(electrodes)\n",
    "    freqs = np.linspace(22, 30, 10)\n",
    "    sepochs2 = mne.Epochs(sraw2, events2 , stim_ids, tmin=tmin, picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs3 = mne.Epochs(sraw3, events3 , stim_ids, tmin=tmin, picks=electrodes, tmax=tmax, baseline=baseline)\n",
    "    sepochs = mne.concatenate_epochs([sepochs2, sepochs3])\n",
    "    tfr = mne.time_frequency.tfr_morlet(sepochs, freqs=freqs, picks='all', n_cycles=8, return_itc=False, average=False)\n",
    "    # Compute the mean power for each trial at the LHB frequencies.\n",
    "    lhbdata = []\n",
    "    for i in range(len(temp_data)):\n",
    "        lhbdata.append(np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int((0)*512):int((1.6)*512)].mean())        \n",
    "    if np.mean(epochs_count.copy().pick_channels(electrodes).get_data(), axis=1)[:, int((0.75) * 512):int((0.75 + 2) * 512)].shape[0] != 150:\n",
    "        lhb_erp[subjidx - 1][:np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)].shape[0]] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "        lhb_erp[subjidx - 1][np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)].shape[0]:] = np.nan\n",
    "    \n",
    "    else:\n",
    "        # Calculate the average power across channels and epochs for a fixed interval after 0.75 seconds and assign it to lhb_erp.\n",
    "        lhb_erp[subjidx-1] = np.mean(np.mean(tfr.data,axis=1),axis=1)[:,int(0.75*512):int((0.75+2)*512)]\n",
    "\n",
    "    # Add the LHB and SSVEP data to the DataFrame.\n",
    "    temp_data['amp_lhb'] = lhbdata\n",
    "    temp_data['amp_cum_ssvep'] = ssvepdata\n",
    "    # Add subject index to the DataFrame.\n",
    "    temp_data['subj_idx'] = subjidx \n",
    "    temp_data['subj_index'] = np.arange(len(temp_data)) \n",
    "    # Concatenate temp_data with the existing DataFrame df.\n",
    "    df=pd.concat([df,temp_data]) \n",
    "df.to_csv('df_task3.csv',index=False)\n",
    "# Save the ERP data and the combined DataFrame to files for later use.\n",
    "np.save('df_task3_lhb',lhb_erp)\n",
    "np.save('df_task3_cpp',cpp_erp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "cpp_erp = np.load('df_task2_cpp.npy')\n",
    "dfs = pd.read_csv('df_task2.csv')\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axes = axes.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):\n",
    "    cpp_erp_ind = cpp_erp[i]\n",
    "    rt = dfs.loc[dfs['subj_idx'] == i + 1, 'rt'].reset_index(drop=True)\n",
    "    \n",
    "    # Get the indices that would sort the reaction times in reverse order\n",
    "    rt_sorted_indices = rt.argsort()[::-1]\n",
    "    rt_sorted = rt.to_numpy()[rt_sorted_indices]\n",
    "    \n",
    "    # Use the sorted indices to reorganize the ERP data\n",
    "    cpp_erp_ind_sorted = cpp_erp_ind[rt_sorted_indices]\n",
    "\n",
    "    # Correctly target the subplot for plotting\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(cpp_erp_ind_sorted, aspect='auto', cmap='viridis')\n",
    "    ax.plot(rt_sorted*512, range(150), color='black')  # Plotting adjusted reaction times\n",
    "\n",
    "    # Add a colorbar to each subplot, adjusting it to the subplot size\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    # Set the title and labels for each subplot\n",
    "    ax.set_title(f'Participant {i + 1}')\n",
    "    ax.set_xlabel('Time Points (divided by 512)')\n",
    "    ax.set_xlim(0, 1000)\n",
    "    ax.set_ylabel('Trials')\n",
    "\n",
    "    # Customize the x-axis ticks\n",
    "    tick_locs = ax.get_xticks()  # Get current locations of ticks\n",
    "    ax.set_xticklabels([f\"{x/512:.2f}\" for x in tick_locs])  # Set custom tick labels\n",
    "\n",
    "# Adjust the layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "ssvep_erp = np.load('df_task2_ssvep.npy')\n",
    "dfs = pd.read_csv('df_task2.csv')\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axes = axes.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):\n",
    "    ssvep_erp_ind = ssvep_erp[i]\n",
    "    rt = dfs.loc[dfs['subj_idx'] == i + 1, 'rt'].reset_index(drop=True)\n",
    "    \n",
    "    # Get the indices that would sort the reaction times in reverse order\n",
    "    rt_sorted_indices = rt.argsort()[::-1]\n",
    "    rt_sorted = rt.to_numpy()[rt_sorted_indices]\n",
    "    \n",
    "    # Use the sorted indices to reorganize the ERP data\n",
    "    ssvep_erp_ind_sorted = ssvep_erp_ind[rt_sorted_indices]\n",
    "\n",
    "    # Correctly target the subplot for plotting\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(ssvep_erp_ind_sorted, aspect='auto', cmap='viridis_r')\n",
    "    ax.plot(rt_sorted*512, range(150), color='black')  # Plotting adjusted reaction times\n",
    "\n",
    "    # Add a colorbar to each subplot, adjusting it to the subplot size\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    # Set the title and labels for each subplot\n",
    "    ax.set_title(f'Participant {i + 1}')\n",
    "    ax.set_xlabel('Time Points (divided by 512)')\n",
    "    ax.set_xlim(0, 1000)\n",
    "    ax.set_ylabel('Trials')\n",
    "\n",
    "    # Customize the x-axis ticks\n",
    "    tick_locs = ax.get_xticks()  # Get current locations of ticks\n",
    "    ax.set_xticklabels([f\"{x/512:.2f}\" for x in tick_locs])  # Set custom tick labels\n",
    "\n",
    "# Adjust the layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "lhb_erp = np.load('df_task2_lhb.npy')\n",
    "dfs = pd.read_csv('df_task2.csv')\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axes = axes.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):\n",
    "    lhb_erp_ind = lhb_erp[i]\n",
    "    rt = dfs.loc[dfs['subj_idx'] == i + 1, 'rt'].reset_index(drop=True)\n",
    "    \n",
    "    # Get the indices that would sort the reaction times in reverse order\n",
    "    rt_sorted_indices = rt.argsort()[::-1]\n",
    "    rt_sorted = rt.to_numpy()[rt_sorted_indices]\n",
    "    \n",
    "    # Use the sorted indices to reorganize the ERP data\n",
    "    lhb_erp_ind_sorted = lhb_erp_ind[rt_sorted_indices]\n",
    "\n",
    "    # Correctly target the subplot for plotting\n",
    "    ax = axes[i]\n",
    "    im = ax.imshow(lhb_erp_ind_sorted, aspect='auto', cmap='viridis_r')\n",
    "    ax.plot(rt_sorted*512, range(150), color='black')  # Plotting adjusted reaction times\n",
    "\n",
    "    # Add a colorbar to each subplot, adjusting it to the subplot size\n",
    "    fig.colorbar(im, ax=ax)\n",
    "\n",
    "    # Set the title and labels for each subplot\n",
    "    ax.set_title(f'Participant {i + 1}')\n",
    "    ax.set_xlabel('Time Points (divided by 512)')\n",
    "    ax.set_xlim(0, 1000)\n",
    "    ax.set_ylabel('Trials')\n",
    "\n",
    "    # Customize the x-axis ticks\n",
    "    tick_locs = ax.get_xticks()  # Get current locations of ticks\n",
    "    ax.set_xticklabels([f\"{x/512:.2f}\" for x in tick_locs])  # Set custom tick labels\n",
    "\n",
    "# Adjust the layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "cpp_erp = np.load('df_task2_cpp.npy')\n",
    "dfs = pd.read_csv('df_task2.csv')\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    cpp_erp_ind = cpp_erp[i]\n",
    "    cpp_erp_mean = np.mean(cpp_erp_ind, axis=0)\n",
    "    cpp_erp_sd = np.std(cpp_erp_ind, axis=0)\n",
    "    # Get the response times for the current 'i' and calculate the mean response time\n",
    "    rt_mean = dfs.loc[dfs['subj_idx'] == i + 1, 'rt'].mean()\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(cpp_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean CPP ERP\n",
    "    axs[i].plot(time_points/512, cpp_erp_mean, label='Mean CPP ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512, cpp_erp_mean - cpp_erp_sd, cpp_erp_mean + cpp_erp_sd, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=rt_mean, color='r', linestyle='--', label='Average RT')\n",
    "\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean CPP ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "ssvep_erp = np.load('df_task2_ssvep.npy')\n",
    "dfs = pd.read_csv('df_task2.csv')\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    ssvep_erp_ind = ssvep_erp[i]\n",
    "    ssvep_erp_mean = np.mean(ssvep_erp_ind, axis=0)\n",
    "    ssvep_erp_sd = np.std(ssvep_erp_ind, axis=0)\n",
    "    # Get the response times for the current 'i' and calculate the mean response time\n",
    "    rt_mean = dfs.loc[dfs['subj_idx'] == i + 1, 'rt'].mean()\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(ssvep_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean ssvep ERP\n",
    "    axs[i].plot(time_points/512, ssvep_erp_mean, label='Mean ssvep ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512, ssvep_erp_mean - ssvep_erp_sd, ssvep_erp_mean + ssvep_erp_sd, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=rt_mean, color='r', linestyle='--', label='Average RT')\n",
    "\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean ssvep ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "lhb_erp = np.load('df_task2_lhb.npy')\n",
    "dfs = pd.read_csv('df_task2.csv')\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    lhb_erp_ind = lhb_erp[i]\n",
    "    lhb_erp_mean = np.mean(lhb_erp_ind, axis=0)\n",
    "    lhb_erp_sd = np.std(lhb_erp_ind, axis=0)\n",
    "    # Get the response times for the current 'i' and calculate the mean response time\n",
    "    rt_mean = dfs.loc[dfs['subj_idx'] == i + 1, 'rt'].mean()\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(lhb_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean lhb ERP\n",
    "    axs[i].plot(time_points/512, lhb_erp_mean, label='Mean lhb ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512, lhb_erp_mean - lhb_erp_sd, lhb_erp_mean + lhb_erp_sd, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=rt_mean, color='r', linestyle='--', label='Average RT')\n",
    "\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean lhb ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "cpp_erp = np.load('df_task2_cpp_resp.npy',allow_pickle=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    cpp_erp_ind = cpp_erp[i]\n",
    "    cpp_erp_mean = np.mean(cpp_erp_ind, axis=0)\n",
    "    cpp_erp_sd = np.std(cpp_erp_ind, axis=0)\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(cpp_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean CPP ERP\n",
    "    axs[i].plot(time_points/512-1.5, cpp_erp_mean, label='Mean CPP ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512-1.5, cpp_erp_mean - cpp_erp_sd, cpp_erp_mean + cpp_erp_sd, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=0, color='grey', linestyle='-')\n",
    "\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean CPP ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "ssvep_erp = np.load('df_task2_ssvep_resp.npy',allow_pickle=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    ssvep_erp_ind = ssvep_erp[i]\n",
    "    ssvep_erp_mean = np.mean(ssvep_erp_ind, axis=0)\n",
    "    ssvep_erp_sd = np.std(ssvep_erp_ind, axis=0)\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(ssvep_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean ssvep ERP\n",
    "    axs[i].plot(time_points/512-1.5, ssvep_erp_mean, label='Mean ssvep ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512-1.5, ssvep_erp_mean - ssvep_erp_sd, ssvep_erp_mean + ssvep_erp_sd, color='lightblue', alpha=0.5)\n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=0, color='grey', linestyle='-')\n",
    "\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean ssvep ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "ssvep_erp = np.load('df_task2_ssvep_resp.npy',allow_pickle=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    ssvep_erp_ind = ssvep_erp[i]\n",
    "    ssvep_erp_mean = np.mean(ssvep_erp_ind, axis=0)\n",
    "    ssvep_erp_sd = np.std(ssvep_erp_ind, axis=0)\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(ssvep_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean ssvep ERP\n",
    "    axs[i].plot(time_points/512-1.5, ssvep_erp_mean, label='Mean ssvep ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512-1.5, ssvep_erp_mean - ssvep_erp_sd, ssvep_erp_mean + ssvep_erp_sd, color='lightblue', alpha=0.5)\n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=0, color='grey', linestyle='-')\n",
    "\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean ssvep ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ERP data and CSV file\n",
    "lhb_erp = np.load('df_task2_lhb_resp.npy',allow_pickle=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))  # Create a subplot with 2 rows and 3 columns\n",
    "axs = axs.ravel()  # Flatten the axis array for easy iteration\n",
    "\n",
    "for i in range(6):  # Assuming there are 6 values for 'i'\n",
    "    # Calculate the mean and standard deviation for the 'i' value\n",
    "    lhb_erp_ind = lhb_erp[i]\n",
    "    lhb_erp_mean = np.mean(lhb_erp_ind, axis=0)\n",
    "    lhb_erp_sd = np.std(lhb_erp_ind, axis=0)\n",
    "\n",
    "    # Time points for x-axis (assuming 1 sample per ms, adjust accordingly)\n",
    "    time_points = np.arange(0, len(lhb_erp_mean))\n",
    "\n",
    "    # Create a line plot for the mean lhb ERP\n",
    "    axs[i].plot(time_points/512-1.5, lhb_erp_mean, label='Mean lhb ERP for i = '+str(i))\n",
    "\n",
    "    # Add shaded area for standard deviation\n",
    "    axs[i].fill_between(time_points/512-1.5, lhb_erp_mean - lhb_erp_sd, lhb_erp_mean + lhb_erp_sd, color='lightblue', alpha=0.5)\n",
    "    \n",
    "    # Add a vertical line for the average response time\n",
    "    axs[i].axvline(x=0, color='grey', linestyle='-')\n",
    "    # Adding labels and title for clarity\n",
    "    axs[i].set_xlabel('Time (ms)')\n",
    "    axs[i].set_ylabel('Amplitude')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set the overall title for the subplot\n",
    "plt.suptitle('Mean lhb ERP with Standard Deviation for Different i Values')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
