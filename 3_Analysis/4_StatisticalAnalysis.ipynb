{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# the variables of the task 2, response condition, attention condition\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_task2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_task2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      3\u001b[0m df_task2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_amp_cpp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_task2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamp_cpp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m df_task2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_amp_lhb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_task2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamp_lhb\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# the variables of the task 2, response condition, attention condition\n",
    "df_task2 = pd.read_csv('df_task2.csv').dropna()\n",
    "df_task2['peak_amp_cpp'] = df_task2['amp_cpp']\n",
    "df_task2['peak_amp_lhb'] = df_task2['amp_lhb']\n",
    "\n",
    "# the variables of the task 1, count condition\n",
    "df_task1 = pd.read_csv('df_task1.csv').dropna()\n",
    "# the variables of the task 1, no attention condition\n",
    "df_task3 = pd.read_csv('df_task3.csv').dropna()\n",
    "\n",
    "# lead the erp\n",
    "cpp_erp = np.load('df_task2_cpp.npy')\n",
    "lhb_erp = np.load('df_task2_lhb.npy')\n",
    "ssvep_erp = np.load('df_task2_ssvep.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1\n",
    "\n",
    "**Question**: Whether CPP has the characteristic of an increase in build-up rate over time.\n",
    "\n",
    "**Method**: (task 2) For each participant to get $r^2_{cpp,raw}$ and $r^2_{cpp,cum}$, a paired sample *t* test was performed on all participants' $r^2_{cpp,raw}$ and $r^2_{cpp,cum}$\n",
    "\n",
    "i is trial, j is participant\n",
    "\n",
    "$$amplitude_{CPP,j} = \\beta_0 + \\beta_1*amplitude_{SSVEP,raw,j}+\\epsilon, r^2_{CPP,raw,j}$$\n",
    "\n",
    "$$amplitude_{CPP,j} = \\beta_0 + \\beta_1*amplitude_{SSVEP,cum,j}+\\epsilon, r^2_{CPP,cum,j}$$\n",
    "\n",
    "$$paired sample t-test(r^2_{CPP,raw},r^2_{CPP,raw})$$\n",
    "\n",
    "**H0**: $$r^2_{CPP,raw} = r^2_{CPP,cum}$$\n",
    "\n",
    "**H1**: $$r^2_{CPP,raw} < r^2_{CPP,cum}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.1051470070960456, pvalue=0.3194167533217742, df=5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r2_cppraw_all = []\n",
    "r2_cppcum_all = []\n",
    "for i in df_task2['subj_idx'].unique():\n",
    "    # transform the series to the matrix\n",
    "    amp_ssvep = df_task2.loc[df_task2['subj_idx']==i,'amp_ssvep'].to_numpy().reshape(-1,1)\n",
    "    amp_cpp = df_task2.loc[df_task2['subj_idx']==i,'amp_cpp'].to_numpy().reshape(-1,1)\n",
    "    amp_ssvep_cum = df_task2.loc[df_task2['subj_idx']==i,'amp_cum_ssvep'].to_numpy().reshape(-1,1)\n",
    "    # linear regression of cpp and ssvep raw\n",
    "    m_cppraw = LinearRegression()\n",
    "    m_cppraw.fit(amp_ssvep,amp_cpp)\n",
    "    r2_cppraw = m_cppraw.score(amp_ssvep,amp_cpp)\n",
    "    # linear regression of cpp and ssvep cum\n",
    "    m_cppcum = LinearRegression()\n",
    "    m_cppcum.fit(amp_ssvep_cum,amp_cpp)\n",
    "    r2_cppcum = m_cppcum.score(amp_ssvep_cum,amp_cpp)\n",
    "    # add the subject r2 to the r2 set\n",
    "    r2_cppraw_all.append(r2_cppraw)\n",
    "    r2_cppcum_all.append(r2_cppcum)\n",
    "# paired sample ttest\n",
    "stats.ttest_rel(r2_cppraw_all,r2_cppcum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004249894755000057"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r2_cppraw_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007323168144315144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r2_cppcum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004011653015243703"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(r2_cppraw_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00616796365899512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(r2_cppcum_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2\n",
    "\n",
    "**Question**: Does LHB have the characteristic characteristic of increasing build-up rate over time.\n",
    "\n",
    "**Method**: (task 2) $r^2_{LHB,raw}$ and $r^2_{LHB,cum}$ were tested for paired-sample *t* for each participant to obtain $r^2_{LHB,raw}$ and $r^2_{LHB,cum}$\n",
    "\n",
    "i is trial, j is participant\n",
    "\n",
    "$$amplitude_{LHB,j} = \\beta_0 + \\beta_1*amplitude_{SSVEP,raw,j}+\\epsilon, r^2_{LHB,raw,j}$$\n",
    "\n",
    "$$amplitude_{LHB,j} = \\beta_0 + \\beta_1*amplitude_{SSVEP,cum,j}+\\epsilon, r^2_{LHB,cum,j}$$\n",
    "\n",
    "$$paired sample t-test(r^2_{LHB,raw},r^2_{LHB,raw})$$\n",
    "\n",
    "**H0**: $$r^2_{LHB,raw} = r^2_{LHB,cum}$$\n",
    "\n",
    "**H1**: $$r^2_{LHB,raw} < r^2_{LHB,cum}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=7.392174821925874, pvalue=0.0007126045716996222, df=5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_lhbraw_all = []\n",
    "r2_lhbcum_all = []\n",
    "for i in df_task2['subj_idx'].unique():\n",
    "    # transform the series to the matrix\n",
    "    amp_ssvep = df_task2.loc[df_task2['subj_idx']==i,'amp_ssvep'].to_numpy().reshape(-1,1)\n",
    "    amp_lhb = df_task2.loc[df_task2['subj_idx']==i,'amp_lhb'].to_numpy().reshape(-1,1)\n",
    "    amp_ssvep_cum = df_task2.loc[df_task2['subj_idx']==i,'amp_cum_ssvep'].to_numpy().reshape(-1,1)\n",
    "    # linear regression of cpp and ssvep raw\n",
    "    m_lhbraw = LinearRegression()\n",
    "    m_lhbraw.fit(amp_ssvep,amp_lhb)\n",
    "    r2_lhbraw = m_lhbraw.score(amp_ssvep,amp_lhb)\n",
    "    # linear regression of cpp and ssvep cum\n",
    "    m_lhbcum = LinearRegression()\n",
    "    m_lhbcum.fit(amp_ssvep_cum,amp_lhb)\n",
    "    r2_lhbcum = m_lhbcum.score(amp_ssvep_cum,amp_lhb)\n",
    "    # add the subject r2 to the r2 set\n",
    "    r2_lhbraw_all.append(r2_lhbraw)\n",
    "    r2_lhbcum_all.append(r2_lhbcum)\n",
    "# paired sample ttest\n",
    "stats.ttest_rel(r2_lhbraw_all,r2_lhbcum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6227484541533627"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r2_lhbraw_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11211753266729646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(r2_lhbcum_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20684400215360027"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(r2_lhbraw_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07471622431285696"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(r2_lhbcum_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H3\n",
    "\n",
    "**Question**:  Does CPP reflect the characteristics of sensory evidence temporal integration better than LHB.\n",
    "\n",
    "**Method**: (task 2) For each participant to get $r^2_{CPP,raw}$ , $r^2_{CPP,cum}$,$r^2_{LHB,raw}$ and $r^2_{LHB,cum}$, a paired sample *t* test was performed on all participants' $r^2_{CPP,raw}$ and $r^2_{LHB,raw}$ , $r^2_{CPP,cum}$ and $r^2_{LHB,cum}$ \n",
    "\n",
    "$$paired \\quad sample \\quad t-test(r^2_{CPP,raw},r^2_{LHB,raw})$$\n",
    "\n",
    "$$paired \\quad sample \\quad t-test(r^2_{CPP,cum},r^2_{LHB,cum})$$\n",
    "\n",
    "\n",
    "**H0**:$$r^2_{CPP,raw} = r^2_{LHB,raw} \\quad and \\quad r^2_{CPP,cum} = r^2_{LHB,cum}$$\n",
    "\n",
    "**H1**:$$r^2_{CPP,raw} > r^2_{LHB,raw} \\quad and \\quad r^2_{CPP,cum} > r^2_{LHB,cum}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-6.7028492390657055, pvalue=0.0011185116726248044, df=5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paired sample ttest of raw ssvep\n",
    "stats.ttest_rel(r2_cppraw_all,r2_lhbraw_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-3.1479891393683217, pvalue=0.02543644957322648, df=5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paired sample ttest of sum ssvep\n",
    "stats.ttest_rel(r2_cppcum_all,r2_lhbcum_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H4\n",
    "\n",
    "**Question**: Does CPP (LHB) have the same characteristics of the same peak amplitude at different RT.\n",
    "\n",
    "**Method**: (task 2) The peak amplitude of CPP (LHB) sorted by RT was obtained for each participant, and repeated measurement ANOVA or [Equivalence test] was performed among all participants\n",
    "\n",
    "$$RMANOVA(PeakAmplitude_{CPP,slow},PeakAmplitude_{CPP,mid},PeakAmplitude_{CPP,fast})$$\n",
    "\n",
    "$$RMANOVA(PeakAmplitude_{LHB,slow},PeakAmplitude_{LHB,mid},PeakAmplitude_{LHB,fast})$$\n",
    "\n",
    "**H0**: $$PeakAmplitude_{CPP,slow} = PeakAmplitude_{CPP,mid} = PeakAmplitude_{CPP,fast}$$ and $$PeakAmplitude_{LHB,slow} = PeakAmplitude_{LHB,mid} = PeakAmplitude_{LHB,fast}$$\n",
    "\n",
    "**H1**:  $$PeakAmplitude_{CPP,slow} \\ne PeakAmplitude_{CPP,mid} \\ne PeakAmplitude_{CPP,fast}$$ and $$PeakAmplitude_{LHB,slow} \\ne PeakAmplitude_{LHB,mid} \\ne PeakAmplitude_{LHB,fast}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_index</th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>rt</th>\n",
       "      <th>amp_cpp</th>\n",
       "      <th>amp_lhb</th>\n",
       "      <th>amp_cum_ssvep</th>\n",
       "      <th>amp_ssvep</th>\n",
       "      <th>pl_ssvep</th>\n",
       "      <th>pl_lhb</th>\n",
       "      <th>pl_cpp</th>\n",
       "      <th>peak_amp_cpp</th>\n",
       "      <th>peak_amp_lhb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.737354</td>\n",
       "      <td>1.899379e-06</td>\n",
       "      <td>3.500680e-11</td>\n",
       "      <td>1.058558e-07</td>\n",
       "      <td>2.261495e-10</td>\n",
       "      <td>1.381958</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.899379e-06</td>\n",
       "      <td>3.500680e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.334752</td>\n",
       "      <td>1.489341e-06</td>\n",
       "      <td>3.536075e-11</td>\n",
       "      <td>1.374979e-07</td>\n",
       "      <td>2.289236e-10</td>\n",
       "      <td>1.147793</td>\n",
       "      <td>1.662109</td>\n",
       "      <td>1.123047</td>\n",
       "      <td>1.489341e-06</td>\n",
       "      <td>3.536075e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.827163</td>\n",
       "      <td>-5.890551e-07</td>\n",
       "      <td>3.668162e-11</td>\n",
       "      <td>1.074111e-07</td>\n",
       "      <td>2.404259e-10</td>\n",
       "      <td>1.166987</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>-5.890551e-07</td>\n",
       "      <td>3.668162e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.112556</td>\n",
       "      <td>2.301828e-06</td>\n",
       "      <td>3.620270e-11</td>\n",
       "      <td>1.449769e-07</td>\n",
       "      <td>2.345322e-10</td>\n",
       "      <td>0.681382</td>\n",
       "      <td>1.925781</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>2.301828e-06</td>\n",
       "      <td>3.620270e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.439887</td>\n",
       "      <td>-8.829081e-07</td>\n",
       "      <td>3.494789e-11</td>\n",
       "      <td>2.592581e-07</td>\n",
       "      <td>2.282788e-10</td>\n",
       "      <td>0.470250</td>\n",
       "      <td>1.177734</td>\n",
       "      <td>1.654297</td>\n",
       "      <td>-8.829081e-07</td>\n",
       "      <td>3.494789e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>1.773284</td>\n",
       "      <td>2.099028e-07</td>\n",
       "      <td>4.871742e-11</td>\n",
       "      <td>2.057052e-07</td>\n",
       "      <td>2.268185e-10</td>\n",
       "      <td>0.214971</td>\n",
       "      <td>0.478516</td>\n",
       "      <td>1.978516</td>\n",
       "      <td>2.099028e-07</td>\n",
       "      <td>4.871742e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>145</td>\n",
       "      <td>6</td>\n",
       "      <td>2.086494</td>\n",
       "      <td>5.316440e-07</td>\n",
       "      <td>5.504989e-11</td>\n",
       "      <td>1.929776e-07</td>\n",
       "      <td>2.195939e-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>0.947266</td>\n",
       "      <td>5.316440e-07</td>\n",
       "      <td>5.504989e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>146</td>\n",
       "      <td>6</td>\n",
       "      <td>1.814620</td>\n",
       "      <td>-1.626596e-07</td>\n",
       "      <td>5.049186e-11</td>\n",
       "      <td>2.048127e-07</td>\n",
       "      <td>2.254640e-10</td>\n",
       "      <td>1.850288</td>\n",
       "      <td>0.494141</td>\n",
       "      <td>1.087891</td>\n",
       "      <td>-1.626596e-07</td>\n",
       "      <td>5.049186e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>147</td>\n",
       "      <td>6</td>\n",
       "      <td>1.599211</td>\n",
       "      <td>7.311582e-07</td>\n",
       "      <td>3.857397e-11</td>\n",
       "      <td>1.913773e-07</td>\n",
       "      <td>2.359002e-10</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>1.740234</td>\n",
       "      <td>7.311582e-07</td>\n",
       "      <td>3.857397e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>2.645294</td>\n",
       "      <td>1.013588e-06</td>\n",
       "      <td>5.504989e-11</td>\n",
       "      <td>2.851511e-07</td>\n",
       "      <td>2.195939e-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.111328</td>\n",
       "      <td>1.130859</td>\n",
       "      <td>1.013588e-06</td>\n",
       "      <td>5.504989e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj_index  subj_idx        rt       amp_cpp       amp_lhb  \\\n",
       "1             1         1  1.737354  1.899379e-06  3.500680e-11   \n",
       "2             2         1  1.334752  1.489341e-06  3.536075e-11   \n",
       "3             3         1  0.827163 -5.890551e-07  3.668162e-11   \n",
       "4             4         1  1.112556  2.301828e-06  3.620270e-11   \n",
       "5             5         1  1.439887 -8.829081e-07  3.494789e-11   \n",
       "..          ...       ...       ...           ...           ...   \n",
       "894         144         6  1.773284  2.099028e-07  4.871742e-11   \n",
       "895         145         6  2.086494  5.316440e-07  5.504989e-11   \n",
       "896         146         6  1.814620 -1.626596e-07  5.049186e-11   \n",
       "897         147         6  1.599211  7.311582e-07  3.857397e-11   \n",
       "899         149         6  2.645294  1.013588e-06  5.504989e-11   \n",
       "\n",
       "     amp_cum_ssvep     amp_ssvep  pl_ssvep    pl_lhb    pl_cpp  peak_amp_cpp  \\\n",
       "1     1.058558e-07  2.261495e-10  1.381958  1.488281  1.125000  1.899379e-06   \n",
       "2     1.374979e-07  2.289236e-10  1.147793  1.662109  1.123047  1.489341e-06   \n",
       "3     1.074111e-07  2.404259e-10  1.166987  0.236328  0.675781 -5.890551e-07   \n",
       "4     1.449769e-07  2.345322e-10  0.681382  1.925781  1.093750  2.301828e-06   \n",
       "5     2.592581e-07  2.282788e-10  0.470250  1.177734  1.654297 -8.829081e-07   \n",
       "..             ...           ...       ...       ...       ...           ...   \n",
       "894   2.057052e-07  2.268185e-10  0.214971  0.478516  1.978516  2.099028e-07   \n",
       "895   1.929776e-07  2.195939e-10  0.000000  1.488281  0.947266  5.316440e-07   \n",
       "896   2.048127e-07  2.254640e-10  1.850288  0.494141  1.087891 -1.626596e-07   \n",
       "897   1.913773e-07  2.359002e-10  0.023033  0.726562  1.740234  7.311582e-07   \n",
       "899   2.851511e-07  2.195939e-10  0.000000  1.111328  1.130859  1.013588e-06   \n",
       "\n",
       "     peak_amp_lhb  \n",
       "1    3.500680e-11  \n",
       "2    3.536075e-11  \n",
       "3    3.668162e-11  \n",
       "4    3.620270e-11  \n",
       "5    3.494789e-11  \n",
       "..            ...  \n",
       "894  4.871742e-11  \n",
       "895  5.504989e-11  \n",
       "896  5.049186e-11  \n",
       "897  3.857397e-11  \n",
       "899  5.504989e-11  \n",
       "\n",
       "[772 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task2['rt_quantile'] = df_task2.groupby('subj_idx')['rt'].apply(lambda x: pd.qcut(x, q=3, labels=['fast', 'mid', 'slow'])).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Anova\n",
      "=========================================\n",
      "            F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------------\n",
      "rt_quantile  2.6961 2.0000 10.0000 0.1157\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\CPP\\lib\\site-packages\\statsmodels\\stats\\anova.py:512: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  self.data = (self.data\n"
     ]
    }
   ],
   "source": [
    "# Anova of the cpp peak amplitide of different rt quantile\n",
    "cpp_aov = AnovaRM(df_task2,\n",
    "                   'peak_amp_cpp',\n",
    "                   'subj_idx',\n",
    "                   within=['rt_quantile'],\n",
    "                   aggregate_func='mean')\n",
    "cpp_aov_res=cpp_aov.fit()\n",
    "print(cpp_aov_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Anova\n",
      "=========================================\n",
      "            F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------------\n",
      "rt_quantile  0.2554 2.0000 10.0000 0.7795\n",
      "=========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\CPP\\lib\\site-packages\\statsmodels\\stats\\anova.py:512: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  self.data = (self.data\n"
     ]
    }
   ],
   "source": [
    "# Anova of the lhb peak amplitide of different rt quantile\n",
    "lhb_aov = AnovaRM(df_task2,\n",
    "                   'peak_amp_lhb',\n",
    "                   'subj_idx',\n",
    "                   within=['rt_quantile'],\n",
    "                   aggregate_func='mean')\n",
    "lhb_aov_res=lhb_aov.fit()\n",
    "print(lhb_aov_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**: (task 2) The peak amplitude of CPP (LHB) sorted by RT was obtained for each participant, and Equivalence test was performed among all participants\n",
    "\n",
    "**H0**: $$PeakAmplitude_{CPP,slow} \\ne PeakAmplitude_{CPP,mid} \\ne PeakAmplitude_{CPP,fast}$$ and $$PeakAmplitude_{LHB,slow} \\ne PeakAmplitude_{LHB,mid} \\ne PeakAmplitude_{LHB,fast}$$\n",
    "\n",
    "**H1**:  $$PeakAmplitude_{CPP,slow} = PeakAmplitude_{CPP,mid} = PeakAmplitude_{CPP,fast}$$ and $$PeakAmplitude_{LHB,slow} = PeakAmplitude_{LHB,mid} = PeakAmplitude_{LHB,fast}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5\n",
    "\n",
    "**Question**: CPP (LHB) reaches a fixed peak amplitude between trials when evidence accumulates that can respond.\n",
    "\n",
    "**Method**: For each participant, the trials and RT correspond in order, and every **5** trials will be composed into a bin, the average amplitude of the time window of **-180ms to -80ms** before response where the peak amplitude is located is calculated, and the peak amplitude in the time window is obtained, and the variance of the peak amplitude between the bins is calculated. After that, the correspondence between the trial and RT is randomly replaced **500** times, and the variance between the displacement bins is obtained under the same step. A paired-sample T-test was performed among all subjects to compare the variance of the peak amplitude under sequential and permutation conditions.\n",
    "\n",
    "\n",
    "$$paired \\quad sample \\quad t-test(Var_{noshuffled}(CPP),Var_{shuffled}(CPP))$$\n",
    "$$paired \\quad sample \\quad t-test(Var_{noshuffled}(LHB),Var_{shuffled}(LHB))$$\n",
    "$$paired \\quad sample \\quad t-test(Var_{noshuffled}(SSVEP),Var_{shuffled}(SSVEP))$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**H0**: $$Var_{noshuffled}(CPP)=Var_{shuffled}(CPP),Var_{noshuffled}(LHB)=Var_{shuffled}(LHB)，Var_{noshuffled}(SSVEP)=Var_{shuffled}(SSVEP)$$\n",
    "\n",
    "**H1**: $$Var_{noshuffled}(CPP) \\ne Var_{shuffled}(CPP),Var_{noshuffled}(LHB) \\ne Var_{shuffled}(LHB)，Var_{noshuffled}(SSVEP) \\ne Var_{shuffled}(SSVEP)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_var(sample_rate,time_window_sp,rawerp,df,iter,shuffled):\n",
    "    # the var of the shuffled value\n",
    "    vars_all = []\n",
    "    for s in range(iter):\n",
    "        vars = []\n",
    "        for i in df['subj_idx'].unique():\n",
    "            rt_sp = (df.loc[df['subj_idx']==i,'rt']*sample_rate).to_numpy().astype(int)\n",
    "            \n",
    "            if shuffled:\n",
    "                np.random.shuffle(rt_sp)\n",
    "            tw = np.column_stack((rt_sp+time_window_sp[0], rt_sp+time_window_sp[1]))\n",
    "           \n",
    "            erps=[]\n",
    "            for j in range(len(df.loc[df['subj_idx']==i,'rt'])):\n",
    "                erp = np.average(rawerp[i-1][j][tw[j][0]:tw[j][1]])\n",
    "                erps.append(erp)\n",
    "                \n",
    "            var = np.nanvar(erps)\n",
    "            \n",
    "            vars.append(var)\n",
    "            \n",
    "            #print(vars)\n",
    "        vars_all.append(vars)\n",
    "    vars_shuffled = np.nanmean(np.array(vars_all),axis=0)\n",
    "    return vars_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 512\n",
    "time_window_sp =(np.array([-0.18,-0.08])*sample_rate).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.069650390990756, pvalue=0.09328109562105924, df=5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the variance of cpp\n",
    "# the var of the raw value\n",
    "var_no_shuffled = shuffled_var(sample_rate = sample_rate,\n",
    "                                time_window_sp=time_window_sp,\n",
    "                                rawerp=cpp_erp,\n",
    "                                df=pd.read_csv('df_task2.csv'),\n",
    "                                iter=500,\n",
    "                                shuffled=False)\n",
    "# the var of the shuffled value\n",
    "var_shuffled = shuffled_var(sample_rate = sample_rate,\n",
    "                                time_window_sp=time_window_sp,\n",
    "                                rawerp=cpp_erp,\n",
    "                                df=pd.read_csv('df_task2.csv'),\n",
    "                                iter=500,\n",
    "                                shuffled=True)\n",
    "# paired sample ttest of raw ssvep\n",
    "stats.ttest_rel(var_no_shuffled,var_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.1276623953750602, pvalue=0.310649215616564, df=5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the variance of lhb\n",
    "# the var of the raw value\n",
    "var_no_shuffled = shuffled_var(sample_rate = sample_rate,\n",
    "                                time_window_sp=time_window_sp,\n",
    "                                rawerp=lhb_erp,\n",
    "                                df=pd.read_csv('df_task2.csv'),\n",
    "                                iter=500,\n",
    "                                shuffled=False)\n",
    "# the var of the shuffled value\n",
    "var_shuffled = shuffled_var(sample_rate = sample_rate,\n",
    "                                time_window_sp=time_window_sp,\n",
    "                                rawerp=lhb_erp,\n",
    "                                df=pd.read_csv('df_task2.csv'),\n",
    "                                iter=500,\n",
    "                                shuffled=True)\n",
    "# paired sample ttest of raw ssvep\n",
    "stats.ttest_rel(var_no_shuffled,var_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.1261625806013087, pvalue=0.08682506240849505, df=5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the variance of ssvep\n",
    "# the var of the raw value\n",
    "var_no_shuffled = shuffled_var(sample_rate = sample_rate,\n",
    "                                time_window_sp=time_window_sp,\n",
    "                                rawerp=ssvep_erp,\n",
    "                                df=pd.read_csv('df_task2.csv'),\n",
    "                                iter=500,\n",
    "                                shuffled=False)\n",
    "# the var of the shuffled value\n",
    "var_shuffled = shuffled_var(sample_rate = sample_rate,\n",
    "                                time_window_sp=time_window_sp,\n",
    "                                rawerp=ssvep_erp,\n",
    "                                df=pd.read_csv('df_task2.csv'),\n",
    "                                iter=500,\n",
    "                                shuffled=True)\n",
    "# paired sample ttest of raw ssvep\n",
    "stats.ttest_rel(var_no_shuffled,var_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H6\n",
    "\n",
    "**Question**: Whether the CPP (LHB) meets the characteristics of responding to a fixed threshold, and CPP better reflects the characteristics of responding to a fixed threshold than LHB.\n",
    "\n",
    "**Method**: (task 2) All trials were arranged in RT order, and all trials were averaged into bins to obtain each group of peak latency and RT, and linear regression was performed.\n",
    "\n",
    "$$Rt = \\beta_0 + \\beta_1*PeakLatency_{CPP,j}+\\epsilon, r^2_{CPP,j}$$\n",
    "\n",
    "$$Rt = \\beta_0 + \\beta_1*PeakLatency_{LHB,j}+\\epsilon, r^2_{LHB,j}$$\n",
    "\n",
    "$$Rt = \\beta_0 + \\beta_1*PeakLatency_{SSVEP,j}+\\epsilon, r^2_{SSVEP,j}$$\n",
    "\n",
    "$$F-test(r^2_{CPP},r^2_{LHB},r^2_{SSVEP})$$\n",
    "\n",
    "**H0**: $$r^2_{CPP}=r^2_{LHB}=r^2_{SSVEP}$$\n",
    "\n",
    "\n",
    "**H1**: $$r^2_{CPP}>r^2_{LHB}>r^2_{SSVEP}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Anova\n",
      "=================================\n",
      "    F Value Num DF  Den DF Pr > F\n",
      "---------------------------------\n",
      "erp  0.0092 2.0000 10.0000 0.9908\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r2_cpp_pl_all = []\n",
    "r2_lhb_pl_all = []\n",
    "r2_ssvep_pl_all = []\n",
    "for i in df_task2['subj_idx'].unique():\n",
    "    # transform the series to the matrix\n",
    "    rt = df_task2.loc[df_task2['subj_idx']==i,'rt'].to_numpy().reshape(-1,1)\n",
    "    pl_ssvep = df_task2.loc[df_task2['subj_idx']==i,'pl_ssvep'].to_numpy().reshape(-1,1)\n",
    "    pl_lhb = df_task2.loc[df_task2['subj_idx']==i,'pl_lhb'].to_numpy().reshape(-1,1)\n",
    "    pl_cpp = df_task2.loc[df_task2['subj_idx']==i,'pl_cpp'].to_numpy().reshape(-1,1)\n",
    "    # linear regression of rt and ssvep peak latency\n",
    "    m_ssveppl = LinearRegression()\n",
    "    m_ssveppl.fit(pl_ssvep,rt)\n",
    "    r2_ssveppl = m_ssveppl.score(pl_ssvep,rt)\n",
    "    # linear regression of rt and lhb peak latency\n",
    "    m_lhbpl = LinearRegression()\n",
    "    m_lhbpl.fit(pl_lhb,rt)\n",
    "    r2_lhbpl = m_lhbpl.score(pl_lhb,rt)\n",
    "    # linear regression of rt and cpp peak latency\n",
    "    m_cpppl = LinearRegression()\n",
    "    m_cpppl.fit(pl_cpp,rt)\n",
    "    r2_cpppl = m_cpppl.score(pl_cpp,rt)\n",
    "    # add the subject r2 to the r2 set\n",
    "    r2_ssvep_pl_all.append(r2_ssveppl)\n",
    "    r2_lhb_pl_all.append(r2_lhbpl)\n",
    "    r2_cpp_pl_all.append(r2_cpppl)\n",
    "# the dataframe used to do anova\n",
    "r2 = r2_ssvep_pl_all + r2_lhb_pl_all +r2_cpp_pl_all\n",
    "erp = ['ssvep']*len(r2_ssvep_pl_all)+['lhb']*len(r2_lhb_pl_all)+['cpp']*len(r2_cpp_pl_all)\n",
    "subj_idxs = np.tile(df_task2['subj_idx'].unique(),3)\n",
    "r2_erp = pd.DataFrame({'r2':r2,\n",
    "                       'erp':erp,\n",
    "                       'subj_idx':subj_idxs})\n",
    "# Anova of the r2 of different erp\n",
    "r2_aov = AnovaRM(r2_erp,\n",
    "                   'r2',\n",
    "                   'subj_idx',\n",
    "                   within=['erp'],\n",
    "                   aggregate_func='mean')\n",
    "r2_aov_res=r2_aov.fit()\n",
    "print(r2_aov_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H7\n",
    "\n",
    "**Question**: Does CPP have the same pattern of evidence accumulation (ERP amplitude) when no motor response is required as it does when a response is required, and does the LHB not have the same pattern of evidence accumulation (ERP amplitude) when no motor response is required.\n",
    "\n",
    "**Method**: (task 3 and 2) Compare the coeffient of the correlation between the CPP and LHB under count condition and response condition. \n",
    "\n",
    "\n",
    "\n",
    "$$paired \\quad sample \\quad t-test(r_{CPP},r_{LHB})$$\n",
    "\n",
    "\n",
    "**H0**: $$r^2_{CPP} = r^2_{LHB}$$\n",
    "\n",
    "**H1**: $$r^2_{CPP} > r^2_{LHB} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -0.9417857050093662, P-value: 0.38954338017578094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:14: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:16: RuntimeWarning: Mean of empty slice\n",
      "  lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:18: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:14: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:16: RuntimeWarning: Mean of empty slice\n",
      "  lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:18: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:14: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:16: RuntimeWarning: Mean of empty slice\n",
      "  lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:18: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:14: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:16: RuntimeWarning: Mean of empty slice\n",
      "  lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:18: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:14: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:16: RuntimeWarning: Mean of empty slice\n",
      "  lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:18: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:14: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:16: RuntimeWarning: Mean of empty slice\n",
      "  lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\3768412754.py:18: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store R² values for CPP and LHB regressions\n",
    "r2_lhbcum_all = []\n",
    "r2_cppcum_all = []\n",
    "\n",
    "# Load the ERP data for task 3\n",
    "cpp_erp_df3 = np.load('df_task3_cpp.npy')  # CPP ERP data for task 3\n",
    "lhb_erp_df3 = np.load('df_task3_lhb.npy')  # LHB ERP data for task 3\n",
    "ssvep_erp_df3 = np.load('df_task3_ssvep.npy')  # SSVEP ERP data for task 3\n",
    "\n",
    "# Compute the cumulative sum of the SSVEP data along the time axis (axis=2)\n",
    "ssvep_cum = np.cumsum(ssvep_erp_df3, axis=2)\n",
    "\n",
    "# Loop through each subject (assuming 6 subjects)\n",
    "for idx in range(6):\n",
    "    # Extract CPP amplitude for task 3 within the time window 1.2 to 1.6 seconds\n",
    "    cpp_amp = np.nanmean(cpp_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    cpp_amp = cpp_amp[~np.isnan(cpp_amp)]  # Remove NaN values\n",
    "    \n",
    "    # Extract LHB amplitude for task 3 within the same time window\n",
    "    lhb_amp = np.nanmean(lhb_erp_df3[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    lhb_amp = lhb_amp[~np.isnan(lhb_amp)]  # Remove NaN values\n",
    "    \n",
    "    # Extract the cumulative SSVEP amplitude for task 3 within the same time window\n",
    "    ssvep_amp = np.nanmean(ssvep_cum[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    ssvep_amp = ssvep_amp[~np.isnan(ssvep_amp)]  # Remove NaN values\n",
    "    \n",
    "    # Reshape the amplitude arrays for linear regression\n",
    "    cpp_amp = cpp_amp.reshape(-1, 1)\n",
    "    lhb_amp = lhb_amp.reshape(-1, 1)\n",
    "    ssvep_amp = ssvep_amp.reshape(-1, 1)\n",
    "    \n",
    "    # Perform linear regression between CPP and cumulative SSVEP\n",
    "    m_cppcum = LinearRegression()\n",
    "    m_cppcum.fit(cpp_amp, ssvep_amp)\n",
    "    r2_cppcum = m_cppcum.score(cpp_amp, ssvep_amp)  # Compute R² for CPP\n",
    "    \n",
    "    # Perform linear regression between LHB and cumulative SSVEP\n",
    "    m_lhbcum = LinearRegression()\n",
    "    m_lhbcum.fit(lhb_amp, ssvep_amp)\n",
    "    r2_lhbcum = m_lhbcum.score(lhb_amp, ssvep_amp)  # Compute R² for LHB\n",
    "    \n",
    "    # Append the R² values for each subject to the corresponding list\n",
    "    r2_lhbcum_all.append(r2_lhbcum)\n",
    "    r2_cppcum_all.append(r2_cppcum)\n",
    "\n",
    "# Perform a paired sample t-test to compare the R² values between CPP and LHB\n",
    "t_stat, p_value = stats.ttest_rel(r2_cppcum_all, r2_lhbcum_all)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H8\n",
    "\n",
    "**Question**: Does CPP not have the same pattern of evidence accumulation (ERP amplitude) under attention transfer conditions and SSVEP has the same pattern of evidence accumulation (ERP amplitude) in both cases.\n",
    "\n",
    "**Method**: (task 1 and 2) Compare the coeffient of the correlation between the CPP under count attention and no attention condition. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$paired \\quad sample \\quad t-test(r_{CPP},r_{LHB})$$\n",
    "\n",
    "\n",
    "**H0**: $$r^2_{CPP} = r^2_{LHB}$$\n",
    "\n",
    "**H1**: $$r^2_{CPP} > r^2_{LHB} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 1.4825094812682795, P-value: 0.19830698556563217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:17: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp_task1 = np.nanmean(cpp_erp_df1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:20: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp_task1 = np.nanmean(ssvep_cum_task1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:17: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp_task1 = np.nanmean(cpp_erp_df1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:20: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp_task1 = np.nanmean(ssvep_cum_task1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:17: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp_task1 = np.nanmean(cpp_erp_df1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:20: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp_task1 = np.nanmean(ssvep_cum_task1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:17: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp_task1 = np.nanmean(cpp_erp_df1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:20: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp_task1 = np.nanmean(ssvep_cum_task1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:17: RuntimeWarning: Mean of empty slice\n",
      "  cpp_amp_task1 = np.nanmean(cpp_erp_df1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5416\\1522574785.py:20: RuntimeWarning: Mean of empty slice\n",
      "  ssvep_amp_task1 = np.nanmean(ssvep_cum_task1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store r-squared values for tasks 1 and 2\n",
    "r2_cppcum_task1s = []\n",
    "r2_cppcum_task2s = []\n",
    "\n",
    "# Load the ERP data for both tasks\n",
    "cpp_erp_df1 = np.load('df_task1_cpp.npy')  # CPP ERP data for task 1\n",
    "ssvep_erp_df1 = np.load('df_task1_ssvep.npy')  # SSVEP ERP data for task 1\n",
    "cpp_erp_df2 = np.load('df_task2_cpp.npy')  # CPP ERP data for task 2\n",
    "ssvep_erp_df2 = np.load('df_task2_ssvep.npy')  # SSVEP ERP data for task 2\n",
    "\n",
    "# Compute the cumulative sum of the SSVEP data along the time axis (axis=2)\n",
    "ssvep_cum_task1 = np.cumsum(ssvep_erp_df1, axis=2)\n",
    "ssvep_cum_task2 = np.cumsum(ssvep_erp_df2, axis=2)\n",
    "\n",
    "# Loop through each subject (assuming 6 subjects)\n",
    "for idx in range(6):\n",
    "    # Extract the CPP amplitude for task 1 in the time window between 1.2 and 1.6 seconds\n",
    "    cpp_amp_task1 = np.nanmean(cpp_erp_df1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    cpp_amp_task1 = cpp_amp_task1[~np.isnan(cpp_amp_task1)]  # Remove NaN values\n",
    "    \n",
    "    # Extract the cumulative SSVEP amplitude for task 1 in the same time window\n",
    "    ssvep_amp_task1 = np.nanmean(ssvep_cum_task1[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    ssvep_amp_task1 = ssvep_amp_task1[~np.isnan(ssvep_amp_task1)]  # Remove NaN values\n",
    "\n",
    "    # Extract the CPP amplitude for task 2 in the time window between 1.2 and 1.6 seconds\n",
    "    cpp_amp_task2 = np.nanmean(cpp_erp_df2[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    cpp_amp_task2 = cpp_amp_task2[~np.isnan(cpp_amp_task2)]  # Remove NaN values\n",
    "\n",
    "    # Extract the cumulative SSVEP amplitude for task 2 in the same time window\n",
    "    ssvep_amp_task2 = np.nanmean(ssvep_cum_task2[idx][:, int(1.2*512):int(1.6*512)], axis=1)\n",
    "    ssvep_amp_task2 = ssvep_amp_task2[~np.isnan(ssvep_amp_task2)]  # Remove NaN values\n",
    "    \n",
    "    # Reshape the CPP and SSVEP amplitudes for linear regression\n",
    "    cpp_amp_task1 = cpp_amp_task1.reshape(-1, 1)\n",
    "    cpp_amp_task2 = cpp_amp_task2.reshape(-1, 1)\n",
    "    ssvep_amp_task1 = ssvep_amp_task1.reshape(-1, 1)\n",
    "    ssvep_amp_task2 = ssvep_amp_task2.reshape(-1, 1)\n",
    "    \n",
    "    # Linear regression for task 1: CPP (independent) vs cumulative SSVEP (dependent)\n",
    "    cppcum_task1 = LinearRegression()\n",
    "    cppcum_task1.fit(cpp_amp_task1, ssvep_amp_task1)\n",
    "    r2_cppcum_task1 = cppcum_task1.score(cpp_amp_task1, ssvep_amp_task1)  # Calculate R² for task 1\n",
    "    \n",
    "    # Linear regression for task 2: CPP (independent) vs cumulative SSVEP (dependent)\n",
    "    cppcum_task2 = LinearRegression()\n",
    "    cppcum_task2.fit(cpp_amp_task2, ssvep_amp_task2)\n",
    "    r2_cppcum_task2 = cppcum_task2.score(cpp_amp_task2, ssvep_amp_task2)  # Calculate R² for task 2\n",
    "    \n",
    "    # Append the R² values to the respective lists for task 1 and task 2\n",
    "    r2_cppcum_task1s.append(r2_cppcum_task1)\n",
    "    r2_cppcum_task2s.append(r2_cppcum_task2)\n",
    "\n",
    "# Perform a paired t-test to compare R² values between task 1 and task 2\n",
    "t_stat, p_value = stats.ttest_rel(r2_cppcum_task1s, r2_cppcum_task2s)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
